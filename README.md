# explainable_AI
Explainable AI (XAI) refers to the set of techniques, methods, and tools developed in the field of artificial intelligence (AI) to make the decision-making processes of AI systems more understandable and transparent to humans.



Here are some key concepts and techniques associated with Explainable AI:

Interpretability: Interpretability refers to the extent to which a human can understand and make sense of an AI system's outputs, predictions, and decision-making processes. This involves understanding why a specific decision was made, which features or data points were important, and how the model arrived at its conclusion.
Model-specific techniques: Different AI models and algorithms have their own methods for providing explanations. For example:
Decision Trees: These models are inherently interpretable because they make decisions based on a series of simple rules that can be visualized.
LIME (Local Interpretable Model-agnostic Explanations): LIME is a technique that approximates a black-box model's behavior with a simpler, more interpretable model for specific instances.
SHAP (SHapley Additive exPlanations): SHAP values allocate contributions of each feature to a model's prediction, providing a way to attribute outcomes to input features.
